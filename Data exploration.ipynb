{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fdc39a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      "                       PaperID  \\\n",
      "184   53e9b857b7602d970441f1ff   \n",
      "194   53e9afeeb7602d9703a40b81   \n",
      "330   53e9b1a3b7602d9703c2d3bb   \n",
      "424   53e9baadb7602d97046dd9ba   \n",
      "655   53e9a2b3b7602d9702bbe857   \n",
      "740   53e9abb2b7602d9703562989   \n",
      "746   53e99f02b7602d97027cf841   \n",
      "871   53e99cf5b7602d97025aa6b5   \n",
      "920   53e9a603b7602d9702f2ec69   \n",
      "966   53e9a7bab7602d97030f78f2   \n",
      "1046  53e99dabb7602d9702669827   \n",
      "1056  53e9b991b7602d970458156e   \n",
      "1061  573698056e3b12023e6dd5f0   \n",
      "1192  53e9ad9eb7602d970379a5e1   \n",
      "1221  53e9b698b7602d9704209cf2   \n",
      "1244  53e9bd98b7602d9704a42252   \n",
      "1360  53e9ba28b7602d9704635bc3   \n",
      "1365  53e99daab7602d97026689be   \n",
      "1382  53e9a12ab7602d9702a192b5   \n",
      "1531  53e9a41cb7602d9702d35b5b   \n",
      "1910  53e9be2eb7602d9704aee27e   \n",
      "1968  53e9a2c8b7602d9702bd2302   \n",
      "1986  53e9b0f5b7602d9703b72e2a   \n",
      "\n",
      "                                                  Title Authors  Year  \\\n",
      "184   Proceedings of the VLDB 2003 PhD Workshop. Co-...     NaN  2003   \n",
      "194   Ordering Information, Conference Organizers, P...     NaN  2000   \n",
      "330             MQSeries and CICS Link for Lotus Notes.     NaN  1996   \n",
      "424   ACT-NET - The Active Database Management Syste...     NaN  1996   \n",
      "655                 Calls for Papers and Announcements.     NaN  1995   \n",
      "740   Science of design for information systems: rep...     NaN  2004   \n",
      "746                 Calls for Papers and Announcements.     NaN  1995   \n",
      "871   The Active Database Central, ER2000, VLDB 2000...     NaN  1999   \n",
      "920   MineSet(tm): A System for High-End Data Mining...     NaN  1996   \n",
      "966   Object-Oriented, Rapid Application Development...     NaN  1995   \n",
      "1046                                              Title     NaN  1995   \n",
      "1056                                      Author Index.     NaN  2000   \n",
      "1061  High-Performance and Scalability through Appli...     NaN  2000   \n",
      "1192  Title, Preface to the Special Issue on Persist...     NaN  1995   \n",
      "1221  Title, Foreword, VLDB Journal to be published ...     NaN  1995   \n",
      "1244  Proceedings of the 2001 ACM SIGMOD internation...     NaN  2001   \n",
      "1360  SHORE: Combining the Best Features of OODBMS a...     NaN  1995   \n",
      "1365  Proceedings of the ACM SIGMOD International Co...     NaN  2004   \n",
      "1382  Proceedings of the 2002 ACM SIGMOD Internation...     NaN  2002   \n",
      "1531  Proceedings of the 2000 ACM SIGMOD Internation...     NaN  2000   \n",
      "1910                    Objectivity Industrial Exhibit.     NaN  1998   \n",
      "1968  Proceedings of the 2003 ACM SIGMOD Internation...     NaN  2003   \n",
      "1986                                Title, Announcement     NaN  1995   \n",
      "\n",
      "                  Venue  \n",
      "184   VLDB PhD Workshop  \n",
      "194                VLDB  \n",
      "330       SIGMOD Record  \n",
      "424       SIGMOD Record  \n",
      "655       SIGMOD Record  \n",
      "740       SIGMOD Record  \n",
      "746       SIGMOD Record  \n",
      "871       SIGMOD Record  \n",
      "920                VLDB  \n",
      "966   SIGMOD Conference  \n",
      "1046            VLDB J.  \n",
      "1056               VLDB  \n",
      "1061               VLDB  \n",
      "1192            VLDB J.  \n",
      "1221            VLDB J.  \n",
      "1244  SIGMOD Conference  \n",
      "1360  SIGMOD Conference  \n",
      "1365  SIGMOD Conference  \n",
      "1382  SIGMOD Conference  \n",
      "1531  SIGMOD Conference  \n",
      "1910               VLDB  \n",
      "1968  SIGMOD Conference  \n",
      "1986            VLDB J.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "df_acm = pd.read_csv('ACM_1995_2004.csv')\n",
    "\n",
    "# Find rows with missing values\n",
    "rows_with_missing = df_acm[df_acm.isnull().any(axis=1)]\n",
    "\n",
    "# Display rows with missing values\n",
    "print(\"Rows with missing values:\")\n",
    "print(rows_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c4609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      "                       PaperID  \\\n",
      "147   5390975920f70186a0dfe08f   \n",
      "174   5390975920f70186a0dfe2a9   \n",
      "179   5390979920f70186a0dffb1f   \n",
      "201   5390979920f70186a0e00d30   \n",
      "202   5390980720f70186a0e01e31   \n",
      "279   53909f6920f70186a0e3a944   \n",
      "1751  5390881820f70186a0d81155   \n",
      "1848  5390882d20f70186a0d8db8e   \n",
      "1880  5390882d20f70186a0d8e3cf   \n",
      "1881  5390878e20f70186a0d39699   \n",
      "1912  539089ab20f70186a0d97021   \n",
      "1913  539089ab20f70186a0d9704f   \n",
      "1930  539089bb20f70186a0d98abc   \n",
      "1931  539089bb20f70186a0d98ac2   \n",
      "1933  539089bb20f70186a0d98acd   \n",
      "1952  558fc3330cf2b02d4688db1f   \n",
      "1953  539089d320f70186a0d9c1e8   \n",
      "1972  558fe6de0cf28af999b579f9   \n",
      "1985  5590deac0cf2baaad97176a2   \n",
      "2172  53908a9620f70186a0da4719   \n",
      "2211  53908a9620f70186a0da4772   \n",
      "2440  53908a9620f70186a0da4f7c   \n",
      "2480  53908b2a20f70186a0db9740   \n",
      "2496  53908b4920f70186a0dbab00   \n",
      "2514  53908b4920f70186a0dbabab   \n",
      "2516  53908b4920f70186a0dbabaa   \n",
      "2525  5390879220f70186a0d3d0a6   \n",
      "2526  5390879220f70186a0d3d0a4   \n",
      "2527  5390879220f70186a0d3d0a7   \n",
      "2530  53908b4920f70186a0dbab63   \n",
      "2532  53908b4920f70186a0dbab5f   \n",
      "2539  53908b4920f70186a0dbab52   \n",
      "2554  53908b4920f70186a0dbabe0   \n",
      "2556  53908b4920f70186a0dbabdf   \n",
      "2559  53908b4920f70186a0dbabe1   \n",
      "2576  53908b4920f70186a0dbabca   \n",
      "2587  5390879220f70186a0d3d0b4   \n",
      "2588  53908b4920f70186a0dbac2b   \n",
      "2593  53908b4920f70186a0dbac58   \n",
      "2597  5390879220f70186a0d3d0c4   \n",
      "2608  53908b4920f70186a0dbabe7   \n",
      "2622  53908b4920f70186a0dbaf9d   \n",
      "2623  53908b4920f70186a0dbb097   \n",
      "2627  53908b4920f70186a0dbb09b   \n",
      "2631  53908b4920f70186a0dbb0a0   \n",
      "2643  53908b4920f70186a0dbb07a   \n",
      "2687  53908b4920f70186a0dbc4f8   \n",
      "2688  53908b4920f70186a0dbc913   \n",
      "2823  558f358f0cf2c779a64785b6   \n",
      "2824  5390879920f70186a0d4119c   \n",
      "2826  5390958a20f70186a0def897   \n",
      "2838  5390958a20f70186a0df012d   \n",
      "2857  5390879920f70186a0d4147d   \n",
      "2869  539095ba20f70186a0df1630   \n",
      "2875  5390962020f70186a0df3f3b   \n",
      "2896  539096cb20f70186a0df787d   \n",
      "\n",
      "                                                  Title Authors  Year  \\\n",
      "147   The VLDB Journal — The International Journal o...     NaN  2004   \n",
      "174                                   ACM SIGMOD Record     NaN  2004   \n",
      "179                                   ACM SIGMOD Record     NaN  2004   \n",
      "201   The VLDB Journal — The International Journal o...     NaN  2004   \n",
      "202                                   ACM SIGMOD Record     NaN  2004   \n",
      "279   Proceedings of the 28th international conferen...     NaN  2002   \n",
      "1751                                  ACM SIGMOD Record     NaN  2002   \n",
      "1848                                  ACM SIGMOD Record     NaN  2002   \n",
      "1880                                  ACM SIGMOD Record     NaN  1995   \n",
      "1881                                  ACM SIGMOD Record     NaN  2002   \n",
      "1912                                  ACM SIGMOD Record     NaN  2001   \n",
      "1913                                  ACM SIGMOD Record     NaN  2001   \n",
      "1930  The VLDB Journal — The International Journal o...     NaN  1995   \n",
      "1931  The VLDB Journal — The International Journal o...     NaN  1995   \n",
      "1933  The VLDB Journal — The International Journal o...     NaN  1995   \n",
      "1952  The VLDB Journal — The International Journal o...     NaN  1995   \n",
      "1953                                  ACM SIGMOD Record     NaN  2002   \n",
      "1972                                  ACM SIGMOD Record     NaN  2003   \n",
      "1985  The VLDB Journal — The International Journal o...     NaN  2002   \n",
      "2172  Ordering Information, Conference Organizers, P...     NaN  2000   \n",
      "2211  High-Performance and Scalability through Appli...     NaN  2000   \n",
      "2440  MineSet(tm): A System for High-End Data Mining...     NaN  1996   \n",
      "2480                                       Author Index     NaN  2000   \n",
      "2496  The VLDB Journal — The International Journal o...     NaN  2000   \n",
      "2514  The VLDB Journal — The International Journal o...     NaN  2000   \n",
      "2516  The VLDB Journal — The International Journal o...     NaN  2000   \n",
      "2525  The VLDB Journal — The International Journal o...     NaN  2001   \n",
      "2526  The VLDB Journal — The International Journal o...     NaN  1999   \n",
      "2527  The VLDB Journal — The International Journal o...     NaN  1999   \n",
      "2530  The VLDB Journal — The International Journal o...     NaN  1998   \n",
      "2532  The VLDB Journal — The International Journal o...     NaN  1998   \n",
      "2539  The VLDB Journal — The International Journal o...     NaN  1998   \n",
      "2554  The VLDB Journal — The International Journal o...     NaN  1997   \n",
      "2556  The VLDB Journal — The International Journal o...     NaN  1997   \n",
      "2559  The VLDB Journal — The International Journal o...     NaN  1997   \n",
      "2576  The VLDB Journal — The International Journal o...     NaN  1998   \n",
      "2587  The VLDB Journal — The International Journal o...     NaN  2000   \n",
      "2588  The VLDB Journal — The International Journal o...     NaN  1996   \n",
      "2593  The VLDB Journal — The International Journal o...     NaN  1996   \n",
      "2597  The VLDB Journal — The International Journal o...     NaN  1996   \n",
      "2608  The VLDB Journal — The International Journal o...     NaN  1997   \n",
      "2622  The VLDB Journal — The International Journal o...     NaN  2001   \n",
      "2623  The VLDB Journal — The International Journal o...     NaN  2002   \n",
      "2627  The VLDB Journal — The International Journal o...     NaN  2001   \n",
      "2631  The VLDB Journal — The International Journal o...     NaN  2001   \n",
      "2643  The VLDB Journal — The International Journal o...     NaN  2002   \n",
      "2687  The VLDB Journal — The International Journal o...     NaN  2003   \n",
      "2688                                  ACM SIGMOD Record     NaN  2003   \n",
      "2823                                  ACM SIGMOD Record     NaN  2003   \n",
      "2824  The VLDB Journal — The International Journal o...     NaN  2003   \n",
      "2826  The VLDB Journal — The International Journal o...     NaN  2003   \n",
      "2838  The VLDB Journal — The International Journal o...     NaN  2003   \n",
      "2857                                  ACM SIGMOD Record     NaN  2003   \n",
      "2869  The VLDB Journal — The International Journal o...     NaN  2004   \n",
      "2875                                  ACM SIGMOD Record     NaN  2004   \n",
      "2896  The VLDB Journal — The International Journal o...     NaN  2004   \n",
      "\n",
      "                                                  Venue  \n",
      "147   The VLDB Journal — The International Journal o...  \n",
      "174                                   ACM SIGMOD Record  \n",
      "179                                   ACM SIGMOD Record  \n",
      "201   The VLDB Journal — The International Journal o...  \n",
      "202                                   ACM SIGMOD Record  \n",
      "279   VLDB '02 Proceedings of the 28th international...  \n",
      "1751                                  ACM SIGMOD Record  \n",
      "1848                                  ACM SIGMOD Record  \n",
      "1880                                  ACM SIGMOD Record  \n",
      "1881                                  ACM SIGMOD Record  \n",
      "1912                                  ACM SIGMOD Record  \n",
      "1913                                  ACM SIGMOD Record  \n",
      "1930  The VLDB Journal — The International Journal o...  \n",
      "1931  The VLDB Journal — The International Journal o...  \n",
      "1933  The VLDB Journal — The International Journal o...  \n",
      "1952  The VLDB Journal — The International Journal o...  \n",
      "1953                                  ACM SIGMOD Record  \n",
      "1972                                  ACM SIGMOD Record  \n",
      "1985  The VLDB Journal — The International Journal o...  \n",
      "2172  VLDB '00 Proceedings of the 26th International...  \n",
      "2211  VLDB '00 Proceedings of the 26th International...  \n",
      "2440  VLDB '96 Proceedings of the 22th International...  \n",
      "2480  VLDB '00 Proceedings of the 26th International...  \n",
      "2496  The VLDB Journal — The International Journal o...  \n",
      "2514  The VLDB Journal — The International Journal o...  \n",
      "2516  The VLDB Journal — The International Journal o...  \n",
      "2525  The VLDB Journal — The International Journal o...  \n",
      "2526  The VLDB Journal — The International Journal o...  \n",
      "2527  The VLDB Journal — The International Journal o...  \n",
      "2530  The VLDB Journal — The International Journal o...  \n",
      "2532  The VLDB Journal — The International Journal o...  \n",
      "2539  The VLDB Journal — The International Journal o...  \n",
      "2554  The VLDB Journal — The International Journal o...  \n",
      "2556  The VLDB Journal — The International Journal o...  \n",
      "2559  The VLDB Journal — The International Journal o...  \n",
      "2576  The VLDB Journal — The International Journal o...  \n",
      "2587  The VLDB Journal — The International Journal o...  \n",
      "2588  The VLDB Journal — The International Journal o...  \n",
      "2593  The VLDB Journal — The International Journal o...  \n",
      "2597  The VLDB Journal — The International Journal o...  \n",
      "2608  The VLDB Journal — The International Journal o...  \n",
      "2622  The VLDB Journal — The International Journal o...  \n",
      "2623  The VLDB Journal — The International Journal o...  \n",
      "2627  The VLDB Journal — The International Journal o...  \n",
      "2631  The VLDB Journal — The International Journal o...  \n",
      "2643  The VLDB Journal — The International Journal o...  \n",
      "2687  The VLDB Journal — The International Journal o...  \n",
      "2688                                  ACM SIGMOD Record  \n",
      "2823                                  ACM SIGMOD Record  \n",
      "2824  The VLDB Journal — The International Journal o...  \n",
      "2826  The VLDB Journal — The International Journal o...  \n",
      "2838  The VLDB Journal — The International Journal o...  \n",
      "2857                                  ACM SIGMOD Record  \n",
      "2869  The VLDB Journal — The International Journal o...  \n",
      "2875                                  ACM SIGMOD Record  \n",
      "2896  The VLDB Journal — The International Journal o...  \n"
     ]
    }
   ],
   "source": [
    "df_dblp = pd.read_csv('DBLP_1995_2004.csv')\n",
    "\n",
    "# Find rows with missing values\n",
    "rows_with_missing = df_dblp[df_dblp.isnull().any(axis=1)]\n",
    "\n",
    "# Display rows with missing values\n",
    "print(\"Rows with missing values:\")\n",
    "print(rows_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8064e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_acm, df_dblp]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e28037ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df_dblp.Title.str.lower().str.split().explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac928fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "for                   814\n",
      "and                   691\n",
      "of                    635\n",
      "the                   634\n",
      "data                  624\n",
      "                     ... \n",
      "reformulation           1\n",
      "enforcing               1\n",
      "revisiting              1\n",
      "commit                  1\n",
      "single-dimensional      1\n",
      "Name: count, Length: 4555, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "923ffb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df_acm.Authors.str.lower().str.split().explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5da9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors\n",
      "j.            175\n",
      "a.            148\n",
      "m.            111\n",
      "s.             95\n",
      "t.             81\n",
      "             ... \n",
      "fagin']         1\n",
      "['takahiro      1\n",
      "'norishige      1\n",
      "murakami',      1\n",
      "'kaixin         1\n",
      "Name: count, Length: 5402, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b3dfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "for             1403\n",
       "and             1218\n",
       "of              1055\n",
       "in               970\n",
       "the              685\n",
       "                ... \n",
       "Box                1\n",
       "Appliance.         1\n",
       "information.       1\n",
       "Continual          1\n",
       "ViSWeb—the         1\n",
       "Name: count, Length: 7795, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.concatenate([x.split() for x in df.Title])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8526511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time: 338.3864710330963 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "df1 = pd.read_csv('ACM_1995_2004.csv')\n",
    "df2 = pd.read_csv('DBLP_1995_2004.csv')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize list to store matched pairs with DataFrame identifiers\n",
    "matches = []\n",
    "\n",
    "# Iterate over rows in df1 and df2 to find matches based on specified conditions\n",
    "for index1, row1 in df1.iterrows():\n",
    "    for index2, row2 in df2.iterrows():\n",
    "        if (row1['Title'] == row2['Title'] and \n",
    "            row1['Authors'] == row2['Authors']):\n",
    "            matches.append((index1, index2, 'ACM', 'DBLP'))  # Store the indices and DataFrame identifiers\n",
    "\n",
    "# Create a DataFrame with matched pairs including DataFrame identifiers\n",
    "matched_pairs_df = pd.DataFrame({'DF1_Index': [pair[0] for pair in matches],\n",
    "                                 'DF2_Index': [pair[1] for pair in matches],\n",
    "                                 'DF1': [pair[2] for pair in matches],\n",
    "                                 'DF2': [pair[3] for pair in matches]})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "matched_pairs_df.to_csv('matched_pairs.csv', index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f\"Total Execution Time: {runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4754669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx1, row1 \u001b[38;5;129;01min\u001b[39;00m df1\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx2, row2 \u001b[38;5;129;01min\u001b[39;00m df2\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 23\u001b[0m         sim \u001b[38;5;241m=\u001b[39m jaccard_similarity(tokenize(row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]), tokenize(row2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     24\u001b[0m         similarities\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACM_Entry\u001b[39m\u001b[38;5;124m'\u001b[39m: idx1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBLP_Entry\u001b[39m\u001b[38;5;124m'\u001b[39m: idx2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m: sim})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create a DataFrame of similarities\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 11\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(text):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(word_tokenize(text\u001b[38;5;241m.\u001b[39mlower()))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\destructive.py:160\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    157\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp, substitution \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPUNCTUATION:\n\u001b[1;32m--> 160\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Handles parentheses.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m regexp, substitution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPARENS_BRACKETS\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\re\\__init__.py:322\u001b[0m, in \u001b[0;36m_subx.<locals>.filter\u001b[1;34m(match, template)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(match, template\u001b[38;5;241m=\u001b[39mtemplate):\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parser\u001b[38;5;241m.\u001b[39mexpand_template(template, match)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\re\\_parser.py:1099\u001b[0m, in \u001b[0;36mexpand_template\u001b[1;34m(template, match)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, group \u001b[38;5;129;01min\u001b[39;00m groups:\n\u001b[1;32m-> 1099\u001b[0m         literals[index] \u001b[38;5;241m=\u001b[39m g(group) \u001b[38;5;129;01mor\u001b[39;00m empty\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid group reference \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m index) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(text):\n",
    "    return set(nltk.word_tokenize(text.lower()))\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Function to calculate similarities\n",
    "def calculate_similarities(threshold=0.9, column_name='Title'):\n",
    "    similarities = []\n",
    "    for idx1, row1 in df1.iterrows():\n",
    "        for idx2, row2 in df2.iterrows():\n",
    "            sim = jaccard_similarity(tokenize(row1[column_name]), tokenize(row2[column_name]))\n",
    "            if sim >= threshold:\n",
    "                similarities.append({'ACM_Entry': idx1, 'DBLP_Entry': idx2, 'Similarity': sim})\n",
    "\n",
    "    return pd.DataFrame(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_year_blocks(dataframe, year_ranges):\n",
    "    blocks = {}\n",
    "    for i, (start, end) in enumerate(year_ranges):\n",
    "        block_name = f'Block_{i+1}'\n",
    "        blocks[block_name] = dataframe[(dataframe['Year'] >= start) & (dataframe['Year'] <= end)]\n",
    "    return blocks\n",
    "\n",
    "# Example usage:\n",
    "# Read your CSV file into a DataFrame\n",
    "df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Define the year ranges\n",
    "custom_ranges = [(2000, 2004), (2005, 2009), (2010, 2014)]  # Add or modify the ranges as needed\n",
    "\n",
    "# Generate blocks based on the year ranges\n",
    "result_blocks = create_year_blocks(df, custom_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.read_csv('ACM_1995_2004.csv')\n",
    "df2 = pd.read_csv('DBLP_1995_2004.csv')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(text):\n",
    "    return set(word_tokenize(text.lower()))\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Set similarity threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Apply tokenization and calculate similarity for each pair of entries\n",
    "similarities = []\n",
    "for idx1, row1 in df1.iterrows():\n",
    "    for idx2, row2 in df2.iterrows():\n",
    "        sim = jaccard_similarity(tokenize(row1['Title']), tokenize(row2['Title']))\n",
    "        if sim >= threshold:\n",
    "            similarities.append({'ACM_Entry': idx1, 'DBLP_Entry': idx2, 'Similarity': sim})\n",
    "\n",
    "# Create a DataFrame of similarities\n",
    "similarity_df = pd.DataFrame(similarities)\n",
    "\n",
    "# Example output of similarity DataFrame\n",
    "print(similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d36da6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9bdef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_acm) + len(df_dblp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4010eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5036"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df[\"PaperID\"].unique()\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cac6e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates_by_column(dataframe, column_name = 'PaperID'):\n",
    "    duplicates = dataframe.groupby(column_name).filter(lambda x: len(x) > 1)\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "double_id = find_duplicates_by_column(df, column_name='PaperID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69a92600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(double_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c113008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(double_id['Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "933761fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>53e99809b7602d970201f67a</td>\n",
       "      <td>Editor's Notes.</td>\n",
       "      <td>['Michael J. Franklin']</td>\n",
       "      <td>1999</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>53e99800b7602d970200b608</td>\n",
       "      <td>Editor's Notes.</td>\n",
       "      <td>['Ling Liu']</td>\n",
       "      <td>2002</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PaperID            Title                  Authors  Year  \\\n",
       "524  53e99809b7602d970201f67a  Editor's Notes.  ['Michael J. Franklin']  1999   \n",
       "635  53e99800b7602d970200b608  Editor's Notes.             ['Ling Liu']  2002   \n",
       "\n",
       "             Venue  \n",
       "524  SIGMOD Record  \n",
       "635  SIGMOD Record  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_duplicates_by_column(double_id, column_name='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9a75a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e9ad33b7602d9703713f2b</td>\n",
       "      <td>Editor's Notes.</td>\n",
       "      <td>['Jennifer Widom']</td>\n",
       "      <td>1995</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53e99792b7602d9701f544b5</td>\n",
       "      <td>Editor's Notes.</td>\n",
       "      <td>['Ling Liu']</td>\n",
       "      <td>2002</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53e9b911b7602d97044f7a6e</td>\n",
       "      <td>Chair's Message.</td>\n",
       "      <td>['Richard T. Snodgrass']</td>\n",
       "      <td>1998</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53e9a611b7602d9702f43a35</td>\n",
       "      <td>Chair's Message.</td>\n",
       "      <td>['M. Tamer Özsu']</td>\n",
       "      <td>2001</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>53e997bab7602d9701fa0b10</td>\n",
       "      <td>Chair's Message.</td>\n",
       "      <td>['M. Tamer Özsu']</td>\n",
       "      <td>2002</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>539095ba20f70186a0df0f11</td>\n",
       "      <td>Review of Data on the Web: from relational to ...</td>\n",
       "      <td>['Fernando Berzal', 'Nicolás Marín']</td>\n",
       "      <td>2003</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>539095ba20f70186a0df0f75</td>\n",
       "      <td>Review of Web caching and replication by Micha...</td>\n",
       "      <td>['Qiang Wang', 'Brian D. Davison']</td>\n",
       "      <td>2003</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>539095ba20f70186a0df1630</td>\n",
       "      <td>The VLDB Journal — The International Journal o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>The VLDB Journal — The International Journal o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>5390962020f70186a0df3f3b</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>539096cb20f70186a0df787d</td>\n",
       "      <td>The VLDB Journal — The International Journal o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>The VLDB Journal — The International Journal o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PaperID  \\\n",
       "3     53e9ad33b7602d9703713f2b   \n",
       "5     53e99792b7602d9701f544b5   \n",
       "12    53e9b911b7602d97044f7a6e   \n",
       "28    53e9a611b7602d9702f43a35   \n",
       "39    53e997bab7602d9701fa0b10   \n",
       "...                        ...   \n",
       "2867  539095ba20f70186a0df0f11   \n",
       "2868  539095ba20f70186a0df0f75   \n",
       "2869  539095ba20f70186a0df1630   \n",
       "2875  5390962020f70186a0df3f3b   \n",
       "2896  539096cb20f70186a0df787d   \n",
       "\n",
       "                                                  Title  \\\n",
       "3                                       Editor's Notes.   \n",
       "5                                       Editor's Notes.   \n",
       "12                                     Chair's Message.   \n",
       "28                                     Chair's Message.   \n",
       "39                                     Chair's Message.   \n",
       "...                                                 ...   \n",
       "2867  Review of Data on the Web: from relational to ...   \n",
       "2868  Review of Web caching and replication by Micha...   \n",
       "2869  The VLDB Journal — The International Journal o...   \n",
       "2875                                  ACM SIGMOD Record   \n",
       "2896  The VLDB Journal — The International Journal o...   \n",
       "\n",
       "                                   Authors  Year  \\\n",
       "3                       ['Jennifer Widom']  1995   \n",
       "5                             ['Ling Liu']  2002   \n",
       "12                ['Richard T. Snodgrass']  1998   \n",
       "28                       ['M. Tamer Özsu']  2001   \n",
       "39                       ['M. Tamer Özsu']  2002   \n",
       "...                                    ...   ...   \n",
       "2867  ['Fernando Berzal', 'Nicolás Marín']  2003   \n",
       "2868    ['Qiang Wang', 'Brian D. Davison']  2003   \n",
       "2869                                   NaN  2004   \n",
       "2875                                   NaN  2004   \n",
       "2896                                   NaN  2004   \n",
       "\n",
       "                                                  Venue  \n",
       "3                                         SIGMOD Record  \n",
       "5                                         SIGMOD Record  \n",
       "12                                        SIGMOD Record  \n",
       "28                                        SIGMOD Record  \n",
       "39                                        SIGMOD Record  \n",
       "...                                                 ...  \n",
       "2867                                  ACM SIGMOD Record  \n",
       "2868                                  ACM SIGMOD Record  \n",
       "2869  The VLDB Journal — The International Journal o...  \n",
       "2875                                  ACM SIGMOD Record  \n",
       "2896  The VLDB Journal — The International Journal o...  \n",
       "\n",
       "[265 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_duplicates_by_column(df, column_name='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dddcd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      PaperID                                Title Authors  \\\n",
      "655  53e9a2b3b7602d9702bbe857  Calls for Papers and Announcements.     NaN   \n",
      "746  53e99f02b7602d97027cf841  Calls for Papers and Announcements.     NaN   \n",
      "\n",
      "     Year          Venue  \n",
      "655  1995  SIGMOD Record  \n",
      "746  1995  SIGMOD Record  \n"
     ]
    }
   ],
   "source": [
    "title_to_find = 'Calls for Papers and Announcements.'\n",
    "\n",
    "# Filter rows based on the title\n",
    "rows_with_same_title = df[df['Title'] == title_to_find]\n",
    "\n",
    "print(rows_with_same_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d29500a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "ACM SIGMOD Record                                                                         40\n",
      "The VLDB Journal — The International Journal on Very Large Data Bases                     35\n",
      "Editor's Notes.                                                                           32\n",
      "Chair's Message.                                                                          18\n",
      "Reminiscences on Influential Papers.                                                      13\n",
      "                                                                                          ..\n",
      "Review - TerraServer: A Spatial Data Warehouse.                                            1\n",
      "Review - The R*-Tree: An Efficient and Robust Access Method for Points and Rectangles.     1\n",
      "Review - Replication and Mobility.                                                         1\n",
      "Review - R-Trees: A Dynamic Index Structure for Spatial Searching.                         1\n",
      "Querying high-dimensional data in single-dimensional space                                 1\n",
      "Name: count, Length: 4848, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "title_counts = df['Title'].value_counts()\n",
    "print(title_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19156e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Year                                                1995  1996  1997  1998  \\\n",
      "Title                                                                        \n",
      "Book review column.                                    0     0     0     0   \n",
      "Calls for Papers and Announcements.                    2     0     0     0   \n",
      "Chair's Message.                                       0     0     1     2   \n",
      "Developments at ACM TODS.                              0     0     0     0   \n",
      "Editor's Notes.                                        2     3     3     3   \n",
      "Guest Editor's Introduction.                           0     0     0     1   \n",
      "Guest editorial.                                       0     0     0     0   \n",
      "Information Director's Message.                        0     0     0     1   \n",
      "Integrating Reliable Memory in Databases.              0     0     1     1   \n",
      "Reminiscences on Influential Papers.                   0     0     0     3   \n",
      "Review - Relational Databases for Querying XML ...     0     0     0     0   \n",
      "Security of Shared Data in Large Systems: State...     0     0     0     0   \n",
      "Treasurer's Message.                                   0     0     0     0   \n",
      "\n",
      "Year                                                1999  2000  2001  2002  \\\n",
      "Title                                                                        \n",
      "Book review column.                                    0     0     0     0   \n",
      "Calls for Papers and Announcements.                    0     0     0     0   \n",
      "Chair's Message.                                       2     3     3     3   \n",
      "Developments at ACM TODS.                              0     0     0     0   \n",
      "Editor's Notes.                                        3     3     3     4   \n",
      "Guest Editor's Introduction.                           0     0     0     2   \n",
      "Guest editorial.                                       0     1     1     0   \n",
      "Information Director's Message.                        0     1     0     0   \n",
      "Integrating Reliable Memory in Databases.              0     0     0     0   \n",
      "Reminiscences on Influential Papers.                   0     3     3     2   \n",
      "Review - Relational Databases for Querying XML ...     1     1     0     0   \n",
      "Security of Shared Data in Large Systems: State...     0     0     0     0   \n",
      "Treasurer's Message.                                   0     1     1     1   \n",
      "\n",
      "Year                                                2003  2004  \n",
      "Title                                                           \n",
      "Book review column.                                    2     0  \n",
      "Calls for Papers and Announcements.                    0     0  \n",
      "Chair's Message.                                       2     2  \n",
      "Developments at ACM TODS.                              1     1  \n",
      "Editor's Notes.                                        4     4  \n",
      "Guest Editor's Introduction.                           0     0  \n",
      "Guest editorial.                                       2     0  \n",
      "Information Director's Message.                        0     0  \n",
      "Integrating Reliable Memory in Databases.              0     0  \n",
      "Reminiscences on Influential Papers.                   2     0  \n",
      "Review - Relational Databases for Querying XML ...     0     0  \n",
      "Security of Shared Data in Large Systems: State...     0     2  \n",
      "Treasurer's Message.                                   1     0  \n"
     ]
    }
   ],
   "source": [
    "duplicated_titles = title_counts[title_counts > 1].index.tolist()\n",
    "\n",
    "# Create a contingency table for duplicated titles\n",
    "cross_tab_duplicated = pd.crosstab(df_acm[df_acm['Title'].isin(duplicated_titles)]['Title'], df_acm['Year'])\n",
    "print(len(cross_tab_duplicated))\n",
    "print(cross_tab_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f39b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       PaperID                      Title  \\\n",
      "408   53e9a099b7602d9702983634  Developments at ACM TODS.   \n",
      "1544  53e9ae04b7602d9703810ef7  Developments at ACM TODS.   \n",
      "\n",
      "                       Authors  Year          Venue  \n",
      "408   ['Richard T. Snodgrass']  2004  SIGMOD Record  \n",
      "1544  ['Richard T. Snodgrass']  2003  SIGMOD Record  \n"
     ]
    }
   ],
   "source": [
    "specific_title = 'Developments at ACM TODS.'\n",
    "\n",
    "# Find rows with the specific title\n",
    "specific_title_rows = df[df['Title'] == specific_title]\n",
    "\n",
    "# Display the rows with the specific title\n",
    "print(specific_title_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49ac3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       PaperID  \\\n",
      "3     53e9ad33b7602d9703713f2b   \n",
      "5     53e99792b7602d9701f544b5   \n",
      "12    53e9b911b7602d97044f7a6e   \n",
      "28    53e9a611b7602d9702f43a35   \n",
      "39    53e997bab7602d9701fa0b10   \n",
      "...                        ...   \n",
      "2820  5590d6820cf2ce4b6f3a0558   \n",
      "2827  5390958a20f70186a0def8e9   \n",
      "2834  5390958a20f70186a0def97b   \n",
      "2846  539095ba20f70186a0df0ea3   \n",
      "2866  539095ba20f70186a0df0f0b   \n",
      "\n",
      "                                                  Title  \\\n",
      "3                                       Editor's Notes.   \n",
      "5                                       Editor's Notes.   \n",
      "12                                     Chair's Message.   \n",
      "28                                     Chair's Message.   \n",
      "39                                     Chair's Message.   \n",
      "...                                                 ...   \n",
      "2820  Review of The data warehouse toolkit: the comp...   \n",
      "2827                       A case for fractured mirrors   \n",
      "2834  Fast and accurate text classification via mult...   \n",
      "2846                                 Book review column   \n",
      "2866  Review of Spatial databases with application t...   \n",
      "\n",
      "                                                Authors  Year  \\\n",
      "3                                    ['Jennifer Widom']  1995   \n",
      "5                                          ['Ling Liu']  2002   \n",
      "12                             ['Richard T. Snodgrass']  1998   \n",
      "28                                    ['M. Tamer Özsu']  2001   \n",
      "39                                    ['M. Tamer Özsu']  2002   \n",
      "...                                                 ...   ...   \n",
      "2820                          ['Alexander A. Anisimov']  2003   \n",
      "2827  ['Ravishankar Ramamurthy', 'David J. DeWitt', ...  2003   \n",
      "2834  ['Soumen Chakrabarti', 'Shourya Roy', 'Mahesh ...  2003   \n",
      "2846                                    ['Karl Aberer']  2003   \n",
      "2866                                  ['Nancy Wiegand']  2003   \n",
      "\n",
      "                                                  Venue  \n",
      "3                                         SIGMOD Record  \n",
      "5                                         SIGMOD Record  \n",
      "12                                        SIGMOD Record  \n",
      "28                                        SIGMOD Record  \n",
      "39                                        SIGMOD Record  \n",
      "...                                                 ...  \n",
      "2820                                  ACM SIGMOD Record  \n",
      "2827  The VLDB Journal — The International Journal o...  \n",
      "2834  The VLDB Journal — The International Journal o...  \n",
      "2846                                  ACM SIGMOD Record  \n",
      "2866                                  ACM SIGMOD Record  \n",
      "\n",
      "[161 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = df.groupby(['Title', 'Authors']).filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Display the rows where 'Title' and 'Authors' occur more than once\n",
    "print(duplicate_rows)\n",
    "len(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cea96014",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdifflib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df1 is the source DataFrame and df2 is the target DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(difflib\u001b[38;5;241m.\u001b[39mget_close_matches(x, df_acm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m'\u001b[39m], cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)), np\u001b[38;5;241m.\u001b[39mnan) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df_dblp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m df_dblp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilarTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdifflib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df1 is the source DataFrame and df2 is the target DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(difflib\u001b[38;5;241m.\u001b[39mget_close_matches(x, df_acm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m'\u001b[39m], cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)), np\u001b[38;5;241m.\u001b[39mnan) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df_dblp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m df_dblp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilarTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\difflib.py:704\u001b[0m, in \u001b[0;36mget_close_matches\u001b[1;34m(word, possibilities, n, cutoff)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m possibilities:\n\u001b[0;32m    703\u001b[0m     s\u001b[38;5;241m.\u001b[39mset_seq1(x)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mreal_quick_ratio() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    705\u001b[0m        s\u001b[38;5;241m.\u001b[39mquick_ratio() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    706\u001b[0m        s\u001b[38;5;241m.\u001b[39mratio() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff:\n\u001b[0;32m    707\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend((s\u001b[38;5;241m.\u001b[39mratio(), x))\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# Move the best scorers to head of list\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\difflib.py:658\u001b[0m, in \u001b[0;36mSequenceMatcher.real_quick_ratio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreal_quick_ratio\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an upper bound on ratio() very quickly.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    This isn't defined beyond that it is an upper bound on .ratio(), and\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m    is faster to compute than either .ratio() or .quick_ratio().\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     la, lb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# can't have more matches than the number of elements in the\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# shorter sequence\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _calculate_ratio(\u001b[38;5;28mmin\u001b[39m(la, lb), la \u001b[38;5;241m+\u001b[39m lb)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# Assuming df1 is the source DataFrame and df2 is the target DataFrame\n",
    "x = [next(iter(difflib.get_close_matches(x, df_acm['Authors'], cutoff=0.6)), np.nan) for x in df_dblp['Authors']]\n",
    "df_dblp['SimilarTitle'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6f97591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Componentized Architecture for Dynamic Electronic Markets.\n",
      "{'PaperID': '53e99800b7602d970200b608', 'Title': 'A Componentized Architecture for Dynamic Electronic Markets.', 'Authors': \"['Benny Reich', 'Israel Ben-Shaul']\", 'Year': 1998, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Advances in Real-Time Database Systems Research.\n",
      "{'PaperID': '53e99809b7602d970201f67a', 'Title': 'Advances in Real-Time Database Systems Research.', 'Authors': \"['Azer Bestavros']\", 'Year': 1996, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: An approach to confidence based page ranking for user oriented Web search.\n",
      "{'PaperID': '53e99809b7602d970201f8e3', 'Title': 'An approach to confidence based page ranking for user oriented Web search.', 'Authors': \"['Debajyoti Mukhopadhyay', 'Debasis Giri', 'Sanasam Ranbir Singh']\", 'Year': 2003, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Bringing Order to Query Optimization.\n",
      "{'PaperID': '53e99b0ab7602d970239c211', 'Title': 'Bringing Order to Query Optimization.', 'Authors': \"['Giedrius Slivinskas', 'Christian S. Jensen', 'Richard T. Snodgrass']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Chair's Message.\n",
      "{'PaperID': '53e99809b7602d970201f8e7', 'Title': \"Chair's Message.\", 'Authors': \"['M. Tamer Özsu']\", 'Year': 2003, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Cluster Validity Methods: Part I.\n",
      "{'PaperID': '53e99809b7602d970201f8e3', 'Title': 'Cluster Validity Methods: Part I.', 'Authors': \"['Maria Halkidi', 'Yannis Batistakis', 'Michalis Vazirgiannis']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Continuous Queries over Data Streams.\n",
      "{'PaperID': '53e99b0ab7602d970239c211', 'Title': 'Continuous Queries over Data Streams.', 'Authors': \"['Shivnath Babu', 'Jennifer Widom']\", 'Year': 2001, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Data Analysis and Mining in the Life Sciences.\n",
      "{'PaperID': '53e99809b7602d970201f8e3', 'Title': 'Data Analysis and Mining in the Life Sciences.', 'Authors': \"['Nam Huyn']\", 'Year': 2001, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Data Bubbles for Non-Vector Data: Speeding-up Hierarchical Clustering in Arbitrary Metric Spaces.\n",
      "{'PaperID': '53e9b884b7602d9704456ace', 'Title': 'Data Bubbles for Non-Vector Data: Speeding-up Hierarchical Clustering in Arbitrary Metric Spaces.', 'Authors': \"['Jianjun Zhou', 'Jörg Sander']\", 'Year': 2003, 'Venue': 'VLDB'}\n",
      "----\n",
      "Title: Database Research: Achievements and Opportunities Into the 21st Century.\n",
      "{'PaperID': '53e99809b7602d970201f8e7', 'Title': 'Database Research: Achievements and Opportunities Into the 21st Century.', 'Authors': \"['Abraham Silberschatz', 'Michael Stonebraker', 'Jeffrey D. Ullman']\", 'Year': 1996, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Declarative Specification of Web Sites with Strudel.\n",
      "{'PaperID': '53e9b884b7602d9704456ace', 'Title': 'Declarative Specification of Web Sites with Strudel.', 'Authors': \"['Mary F. Fernández', 'Daniela Florescu', 'Alon Y. Levy', 'Dan Suciu']\", 'Year': 2000, 'Venue': 'VLDB J.'}\n",
      "----\n",
      "Title: Diluting ACID.\n",
      "{'PaperID': '53e99809b7602d970201f8e7', 'Title': 'Diluting ACID.', 'Authors': \"['Tim Kempster', 'Colin Stirling', 'Peter Thanisch']\", 'Year': 1999, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Editor's Notes.\n",
      "{'PaperID': '53e99809b7602d970201f67a', 'Title': \"Editor's Notes.\", 'Authors': \"['Michael J. Franklin']\", 'Year': 1999, 'Venue': 'SIGMOD Record'}\n",
      "{'PaperID': '53e99800b7602d970200b608', 'Title': \"Editor's Notes.\", 'Authors': \"['Ling Liu']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Energy and rate based MAC protocol for wireless sensor networks.\n",
      "{'PaperID': '53e99800b7602d970200b608', 'Title': 'Energy and rate based MAC protocol for wireless sensor networks.', 'Authors': \"['Rajgopal Kannan', 'Ramaraju Kalidindi', 'S. Sitharama Iyengar', 'Vijay Kumar']\", 'Year': 2003, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Florida International University High Performance Database Research Center.\n",
      "{'PaperID': '53e99809b7602d970201f8e3', 'Title': 'Florida International University High Performance Database Research Center.', 'Authors': \"['Naphtali Rishe', 'Wei Sun 0002', 'David Barton', 'Yi Deng', 'Cyril U. Orji', 'Michael Alexopoulos', 'Leonard Loureiro', 'Carlos Ordonez 0002', 'Mario Sanchez', 'Artyom Shaposhnikov']\", 'Year': 1995, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Foundations of Statistical Natural Language Processing - Book Review.\n",
      "{'PaperID': '53e99800b7602d970200b5fd', 'Title': 'Foundations of Statistical Natural Language Processing - Book Review.', 'Authors': \"['Gerhard Weikum']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Google in a Box - Building the Google Search Appliance.\n",
      "{'PaperID': '53e99800b7602d970200b61f', 'Title': 'Google in a Box - Building the Google Search Appliance.', 'Authors': \"['Narayanan Shivakumar']\", 'Year': 2003, 'Venue': 'SIGMOD Conference'}\n",
      "----\n",
      "Title: High-Performance Extensible Indexing.\n",
      "{'PaperID': '53e9bd37b7602d97049c282f', 'Title': 'High-Performance Extensible Indexing.', 'Authors': \"['Marcel Kornacker']\", 'Year': 1999, 'Venue': 'VLDB'}\n",
      "----\n",
      "Title: Instance-based attribute identification in database integration.\n",
      "{'PaperID': '53e9af33b7602d970396e8cc', 'Title': 'Instance-based attribute identification in database integration.', 'Authors': \"['Cecil Chua Eng Huang', 'Roger H. L. Chiang', 'Ee-Peng Lim']\", 'Year': 2003, 'Venue': 'VLDB J.'}\n",
      "----\n",
      "Title: Managing uncertainty in sensor database.\n",
      "{'PaperID': '53e99800b7602d970200b61f', 'Title': 'Managing uncertainty in sensor database.', 'Authors': \"['Reynold Cheng', 'Sunil Prabhakar']\", 'Year': 2003, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Oracle RAC: Architecture and Performance.\n",
      "{'PaperID': '53e9be4ab7602d9704b05415', 'Title': 'Oracle RAC: Architecture and Performance.', 'Authors': \"['Angelo Pruscino']\", 'Year': 2003, 'Venue': 'SIGMOD Conference'}\n",
      "----\n",
      "Title: PIX: Exact and Approximate Phrase Matching in XML.\n",
      "{'PaperID': '53e9be4ab7602d9704b05415', 'Title': 'PIX: Exact and Approximate Phrase Matching in XML.', 'Authors': \"['Sihem Amer-Yahia', 'Mary F. Fernández', 'Divesh Srivastava', 'Yu Xu']\", 'Year': 2003, 'Venue': 'SIGMOD Conference'}\n",
      "----\n",
      "Title: Performance of Future Database Systems: Bottlenecks and Bonananzas\n",
      "{'PaperID': '53e9bd37b7602d97049c282f', 'Title': 'Performance of Future Database Systems: Bottlenecks and Bonananzas', 'Authors': \"['Chaitanya K. Baru']\", 'Year': 1996, 'Venue': 'VLDB'}\n",
      "----\n",
      "Title: Phoenix Project: Fault-Tolerant Applications.\n",
      "{'PaperID': '53e99800b7602d970200b601', 'Title': 'Phoenix Project: Fault-Tolerant Applications.', 'Authors': \"['Roger S. Barga', 'David B. Lomet']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Report on FQAS 2002: fifth international conference on flexible query answering systems.\n",
      "{'PaperID': '53e99800b7602d970200b601', 'Title': 'Report on FQAS 2002: fifth international conference on flexible query answering systems.', 'Authors': \"['Amihai Motro', 'Troels Andreasen']\", 'Year': 2003, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Research in Information Managment at Dublin City University.\n",
      "{'PaperID': '53e99800b7602d970200b616', 'Title': 'Research in Information Managment at Dublin City University.', 'Authors': \"['Mark Roantree', 'Alan F. Smeaton']\", 'Year': 2002, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: The Evolution of Effective B-tree: Page Organization and Techniques: A Personal Account.\n",
      "{'PaperID': '53e99800b7602d970200b60b', 'Title': 'The Evolution of Effective B-tree: Page Organization and Techniques: A Personal Account.', 'Authors': \"['David B. Lomet']\", 'Year': 2001, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules of Thumb.\n",
      "{'PaperID': '53e99800b7602d970200b616', 'Title': 'The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules of Thumb.', 'Authors': \"['Jim Gray', 'Goetz Graefe']\", 'Year': 1997, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Towards On-Line Analytical Mining in Large Databases.\n",
      "{'PaperID': '53e99800b7602d970200b60b', 'Title': 'Towards On-Line Analytical Mining in Large Databases.', 'Authors': \"['Jiawei Han']\", 'Year': 1998, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Tuple Routing Strategies for Distributed Eddies.\n",
      "{'PaperID': '53e9af33b7602d970396e8cc', 'Title': 'Tuple Routing Strategies for Distributed Eddies.', 'Authors': \"['Feng Tian', 'David J. DeWitt']\", 'Year': 2003, 'Venue': 'VLDB'}\n",
      "----\n",
      "Title: Virtual Database technology.\n",
      "{'PaperID': '53e99800b7602d970200b5fd', 'Title': 'Virtual Database technology.', 'Authors': \"['Ashish Gupta 0001', 'Venky Harinarayan', 'Anand Rajaraman']\", 'Year': 1997, 'Venue': 'SIGMOD Record'}\n",
      "----\n",
      "Title: Why And How To Benchmark XML Databases.\n",
      "{'PaperID': '53e99b0ab7602d970239c211', 'Title': 'Why And How To Benchmark XML Databases.', 'Authors': \"['Albrecht Schmidt 0002', 'Florian Waas', 'Martin L. Kersten', 'Daniela Florescu', 'Michael J. Carey', 'Ioana Manolescu', 'Ralph Busse']\", 'Year': 2001, 'Venue': 'SIGMOD Record'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "title_groups = double_id.groupby('Title').apply(lambda x: x.to_dict('records')).to_dict()\n",
    "\n",
    "# Print each unique title along with its rows\n",
    "for title, rows in title_groups.items():\n",
    "    print(f\"Title: {title}\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9dd3634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       PaperID  \\\n",
      "13    53e99809b7602d970201f8e3   \n",
      "55    53e99800b7602d970200b601   \n",
      "66    53e99b0ab7602d970239c211   \n",
      "101   53e99809b7602d970201f8e3   \n",
      "125   53e99b0ab7602d970239c211   \n",
      "159   53e99800b7602d970200b608   \n",
      "165   53e99800b7602d970200b61f   \n",
      "283   53e99809b7602d970201f8e3   \n",
      "300   53e99800b7602d970200b601   \n",
      "310   53e99809b7602d970201f8e7   \n",
      "428   53e99809b7602d970201f8e7   \n",
      "492   53e9b884b7602d9704456ace   \n",
      "524   53e99809b7602d970201f67a   \n",
      "525   53e99800b7602d970200b5fd   \n",
      "564   53e9be4ab7602d9704b05415   \n",
      "635   53e99800b7602d970200b608   \n",
      "637   53e99800b7602d970200b5fd   \n",
      "643   53e99800b7602d970200b60b   \n",
      "662   53e99800b7602d970200b616   \n",
      "670   53e99b0ab7602d970239c211   \n",
      "673   53e99809b7602d970201f8e3   \n",
      "703   53e99800b7602d970200b616   \n",
      "726   53e99800b7602d970200b608   \n",
      "747   53e99809b7602d970201f67a   \n",
      "862   53e9bd37b7602d97049c282f   \n",
      "1006  53e9bd37b7602d97049c282f   \n",
      "1017  53e9af33b7602d970396e8cc   \n",
      "1194  53e9af33b7602d970396e8cc   \n",
      "1240  53e9be4ab7602d9704b05415   \n",
      "1783  53e9b884b7602d9704456ace   \n",
      "1810  53e99800b7602d970200b61f   \n",
      "1921  53e99809b7602d970201f8e7   \n",
      "2129  53e99800b7602d970200b60b   \n",
      "\n",
      "                                                  Title  \\\n",
      "13    An approach to confidence based page ranking f...   \n",
      "55        Phoenix Project: Fault-Tolerant Applications.   \n",
      "66                Bringing Order to Query Optimization.   \n",
      "101                   Cluster Validity Methods: Part I.   \n",
      "125             Why And How To Benchmark XML Databases.   \n",
      "159   A Componentized Architecture for Dynamic Elect...   \n",
      "165            Managing uncertainty in sensor database.   \n",
      "283   Florida International University High Performa...   \n",
      "300   Report on FQAS 2002: fifth international confe...   \n",
      "310   Database Research: Achievements and Opportunit...   \n",
      "428                                    Chair's Message.   \n",
      "492   Data Bubbles for Non-Vector Data: Speeding-up ...   \n",
      "524                                     Editor's Notes.   \n",
      "525                        Virtual Database technology.   \n",
      "564           Oracle RAC: Architecture and Performance.   \n",
      "635                                     Editor's Notes.   \n",
      "637   Foundations of Statistical Natural Language Pr...   \n",
      "643   Towards On-Line Analytical Mining in Large Dat...   \n",
      "662   The Five-Minute Rule Ten Years Later, and Othe...   \n",
      "670               Continuous Queries over Data Streams.   \n",
      "673      Data Analysis and Mining in the Life Sciences.   \n",
      "703   Research in Information Managment at Dublin Ci...   \n",
      "726   Energy and rate based MAC protocol for wireles...   \n",
      "747    Advances in Real-Time Database Systems Research.   \n",
      "862   Performance of Future Database Systems: Bottle...   \n",
      "1006              High-Performance Extensible Indexing.   \n",
      "1017   Tuple Routing Strategies for Distributed Eddies.   \n",
      "1194  Instance-based attribute identification in dat...   \n",
      "1240  PIX: Exact and Approximate Phrase Matching in ...   \n",
      "1783  Declarative Specification of Web Sites with St...   \n",
      "1810  Google in a Box - Building the Google Search A...   \n",
      "1921                                     Diluting ACID.   \n",
      "2129  The Evolution of Effective B-tree: Page Organi...   \n",
      "\n",
      "                                                Authors  Year  \\\n",
      "13    ['Debajyoti Mukhopadhyay', 'Debasis Giri', 'Sa...  2003   \n",
      "55                 ['Roger S. Barga', 'David B. Lomet']  2002   \n",
      "66    ['Giedrius Slivinskas', 'Christian S. Jensen',...  2002   \n",
      "101   ['Maria Halkidi', 'Yannis Batistakis', 'Michal...  2002   \n",
      "125   ['Albrecht Schmidt 0002', 'Florian Waas', 'Mar...  2001   \n",
      "159                 ['Benny Reich', 'Israel Ben-Shaul']  1998   \n",
      "165                ['Reynold Cheng', 'Sunil Prabhakar']  2003   \n",
      "283   ['Naphtali Rishe', 'Wei Sun 0002', 'David Bart...  1995   \n",
      "300                ['Amihai Motro', 'Troels Andreasen']  2003   \n",
      "310   ['Abraham Silberschatz', 'Michael Stonebraker'...  1996   \n",
      "428                                   ['M. Tamer Özsu']  2003   \n",
      "492                     ['Jianjun Zhou', 'Jörg Sander']  2003   \n",
      "524                             ['Michael J. Franklin']  1999   \n",
      "525   ['Ashish Gupta 0001', 'Venky Harinarayan', 'An...  1997   \n",
      "564                                 ['Angelo Pruscino']  2003   \n",
      "635                                        ['Ling Liu']  2002   \n",
      "637                                  ['Gerhard Weikum']  2002   \n",
      "643                                      ['Jiawei Han']  1998   \n",
      "662                        ['Jim Gray', 'Goetz Graefe']  1997   \n",
      "670                 ['Shivnath Babu', 'Jennifer Widom']  2001   \n",
      "673                                        ['Nam Huyn']  2001   \n",
      "703                ['Mark Roantree', 'Alan F. Smeaton']  2002   \n",
      "726   ['Rajgopal Kannan', 'Ramaraju Kalidindi', 'S. ...  2003   \n",
      "747                                  ['Azer Bestavros']  1996   \n",
      "862                               ['Chaitanya K. Baru']  1996   \n",
      "1006                               ['Marcel Kornacker']  1999   \n",
      "1017                   ['Feng Tian', 'David J. DeWitt']  2003   \n",
      "1194  ['Cecil Chua Eng Huang', 'Roger H. L. Chiang',...  2003   \n",
      "1240  ['Sihem Amer-Yahia', 'Mary F. Fernández', 'Div...  2003   \n",
      "1783  ['Mary F. Fernández', 'Daniela Florescu', 'Alo...  2000   \n",
      "1810                           ['Narayanan Shivakumar']  2003   \n",
      "1921  ['Tim Kempster', 'Colin Stirling', 'Peter Than...  1999   \n",
      "2129                                 ['David B. Lomet']  2001   \n",
      "\n",
      "                  Venue  \n",
      "13        SIGMOD Record  \n",
      "55        SIGMOD Record  \n",
      "66        SIGMOD Record  \n",
      "101       SIGMOD Record  \n",
      "125       SIGMOD Record  \n",
      "159       SIGMOD Record  \n",
      "165       SIGMOD Record  \n",
      "283       SIGMOD Record  \n",
      "300       SIGMOD Record  \n",
      "310       SIGMOD Record  \n",
      "428       SIGMOD Record  \n",
      "492                VLDB  \n",
      "524       SIGMOD Record  \n",
      "525       SIGMOD Record  \n",
      "564   SIGMOD Conference  \n",
      "635       SIGMOD Record  \n",
      "637       SIGMOD Record  \n",
      "643       SIGMOD Record  \n",
      "662       SIGMOD Record  \n",
      "670       SIGMOD Record  \n",
      "673       SIGMOD Record  \n",
      "703       SIGMOD Record  \n",
      "726       SIGMOD Record  \n",
      "747       SIGMOD Record  \n",
      "862                VLDB  \n",
      "1006               VLDB  \n",
      "1017               VLDB  \n",
      "1194            VLDB J.  \n",
      "1240  SIGMOD Conference  \n",
      "1783            VLDB J.  \n",
      "1810  SIGMOD Conference  \n",
      "1921      SIGMOD Record  \n",
      "2129      SIGMOD Record  \n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame containing the entries\n",
    "\n",
    "# Group by 'PaperID' and filter for groups with more than 1 entry\n",
    "duplicates = df_acm.groupby('PaperID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Show all entries for the duplicate PaperIDs\n",
    "if not duplicates.empty:\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicate entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1f2b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_acm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2087bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame (Horizontal):\n",
      "                       PaperID  \\\n",
      "0     5390972920f70186a0dfac5e   \n",
      "1     5390972920f70186a0dfac51   \n",
      "2     5390972920f70186a0dfac57   \n",
      "3     5390972920f70186a0dfac8d   \n",
      "4     5390972920f70186a0dfac88   \n",
      "...                        ...   \n",
      "2897  539096cb20f70186a0df787c   \n",
      "2898  539096cb20f70186a0df7894   \n",
      "2899  558ff72c0cf2e9668dc4d30e   \n",
      "2900  539096cb20f70186a0df7969   \n",
      "2901  539096cb20f70186a0df796e   \n",
      "\n",
      "                                                  Title  \\\n",
      "0                          The next database revolution   \n",
      "1         The role of cryptography in database security   \n",
      "2     Tree logical classes for efficient evaluation ...   \n",
      "3     Adaptive stream resource management using Kalm...   \n",
      "4                    Holistic UDAFs at streaming speeds   \n",
      "...                                                 ...   \n",
      "2897  ViSWeb—the Visual Semantic Web: unifying human...   \n",
      "2898                       Amit - the situation manager   \n",
      "2899  Evolutionary techniques for updating query cos...   \n",
      "2900  Evaluating holistic aggregators efficiently fo...   \n",
      "2901  Querying high-dimensional data in single-dimen...   \n",
      "\n",
      "                                                Authors  Year  \\\n",
      "0                                          ['Jim Gray']  2004   \n",
      "1                                       ['Ueli Maurer']  2004   \n",
      "2     ['Stelios Paparizos', 'Yuqing Wu', 'Laks V. S....  2004   \n",
      "3     ['Ankur Jain', 'Edward Y. Chang', 'Yuan-Fang W...  2004   \n",
      "4     ['Graham Cormode', 'Theodore Johnson', 'Flip K...  2004   \n",
      "...                                                 ...   ...   \n",
      "2897                                       ['Dov Dori']  2004   \n",
      "2898                       ['Asaf Adi', 'Opher Etzion']  2004   \n",
      "2899     ['Amira Rahal', 'Qiang Zhu', 'Per-Åke Larson']  2004   \n",
      "2900            ['Lixin Fu', 'Sanguthevar Rajasekaran']  2004   \n",
      "2901  ['Cui Yu', 'Stéphane Bressan', 'Beng Chin Ooi'...  2004   \n",
      "\n",
      "                                                  Venue  \\\n",
      "0     SIGMOD '04 Proceedings of the 2004 ACM SIGMOD ...   \n",
      "1     SIGMOD '04 Proceedings of the 2004 ACM SIGMOD ...   \n",
      "2     SIGMOD '04 Proceedings of the 2004 ACM SIGMOD ...   \n",
      "3     SIGMOD '04 Proceedings of the 2004 ACM SIGMOD ...   \n",
      "4     SIGMOD '04 Proceedings of the 2004 ACM SIGMOD ...   \n",
      "...                                                 ...   \n",
      "2897  The VLDB Journal — The International Journal o...   \n",
      "2898  The VLDB Journal — The International Journal o...   \n",
      "2899  The VLDB Journal — The International Journal o...   \n",
      "2900  The VLDB Journal — The International Journal o...   \n",
      "2901  The VLDB Journal — The International Journal o...   \n",
      "\n",
      "                       PaperID  \\\n",
      "0     53e998a3b7602d97020ddb24   \n",
      "1     53e9ab20b7602d97034a8f2b   \n",
      "2     53e9b275b7602d9703d174f6   \n",
      "3     53e9ad33b7602d9703713f2b   \n",
      "4     53e99800b7602d970200b618   \n",
      "...                        ...   \n",
      "2897                       NaN   \n",
      "2898                       NaN   \n",
      "2899                       NaN   \n",
      "2900                       NaN   \n",
      "2901                       NaN   \n",
      "\n",
      "                                                  Title  \\\n",
      "0              An initial study of overheads of eddies.   \n",
      "1     Engineering Federated Information Systems: Rep...   \n",
      "2     Information Finding in a Digital Library: The ...   \n",
      "3                                       Editor's Notes.   \n",
      "4     Report on the 5th international workshop on th...   \n",
      "...                                                 ...   \n",
      "2897                                                NaN   \n",
      "2898                                                NaN   \n",
      "2899                                                NaN   \n",
      "2900                                                NaN   \n",
      "2901                                                NaN   \n",
      "\n",
      "                                                Authors    Year          Venue  \n",
      "0                                    ['Amol Deshpande']  2004.0  SIGMOD Record  \n",
      "1     ['Stefan Conrad', 'Wilhelm Hasselbring', 'Uwe ...  1999.0  SIGMOD Record  \n",
      "2                ['Tak W. Yan', 'Hector Garcia-Molina']  1995.0  SIGMOD Record  \n",
      "3                                    ['Jennifer Widom']  1995.0  SIGMOD Record  \n",
      "4     ['Hans-Joachim Lenz', 'Panos Vassiliadis', 'Ma...  2003.0  SIGMOD Record  \n",
      "...                                                 ...     ...            ...  \n",
      "2897                                                NaN     NaN            NaN  \n",
      "2898                                                NaN     NaN            NaN  \n",
      "2899                                                NaN     NaN            NaN  \n",
      "2900                                                NaN     NaN            NaN  \n",
      "2901                                                NaN     NaN            NaN  \n",
      "\n",
      "[2902 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "result_horizontal = pd.concat([df_dblp, df_acm], axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(\"Concatenated DataFrame (Horizontal):\")\n",
    "print(result_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47e5c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.682855143456963\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "file1 = 'file1.csv'\n",
    "file2 = 'file2.csv'\n",
    "\n",
    "df1 = df_acm\n",
    "df2 = df_dblp\n",
    "\n",
    "# Function to split text into words and create a set of words\n",
    "def text_to_set(text):\n",
    "    return set(text.lower().split())\n",
    "\n",
    "# Get sets of words from the 'Title' columns in both DataFrames\n",
    "text_set_1 = text_to_set(' '.join(df1['Authors'].dropna()))\n",
    "text_set_2 = text_to_set(' '.join(df2['Authors'].dropna()))\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = jaccard_similarity(text_set_1, text_set_2)\n",
    "print(f\"Jaccard Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95c1012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Index: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16432\\1971802609.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_acm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Row Index: {index}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Column Name: {col_name}, Value: {col_value}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "for index, row in df_acm.iterrows():\n",
    "    print(f\"Row Index: {index}\")\n",
    "    for col_name, col_value in row.iteritems():\n",
    "        print(f\"Column Name: {col_name}, Value: {col_value}\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac742730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

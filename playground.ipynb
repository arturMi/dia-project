{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    set1_upper = {element.upper() for element in set1}\n",
    "    set2_upper = {element.upper() for element in set2}\n",
    "\n",
    "    intersection = len(set1_upper.intersection(set2_upper))\n",
    "    union = len(set1_upper.union(set2_upper))\n",
    "    \n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = jaccard_similarity('dog', 'dogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trigrams(text: str) -> set:\n",
    "    \"\"\"\n",
    "    returns a set of ngrams for the given string\n",
    "    :param text: the string to find ngrams for\n",
    "    :param number: the length the ngrams should be. defaults to 3 (trigrams)\n",
    "    :return: set of ngram strings\n",
    "    \"\"\"\n",
    "\n",
    "    if not text:\n",
    "        return set()\n",
    "\n",
    "    words = [f'  {x} ' for x in re.split(r'\\W+', text.lower()) if x.strip()]\n",
    "\n",
    "    ngrams = set()\n",
    "\n",
    "    for word in words:\n",
    "        for x in range(0, len(word) - 4):\n",
    "            ngrams.add(word[x:x+3])\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MATT', 'BÖHM'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(text):\n",
    "    if isinstance(text, str):  \n",
    "        return set(nltk.word_tokenize(text.upper()))\n",
    "    else:\n",
    "        return set()\n",
    "    \n",
    "list1 = tokenize('Matt Böhm')\n",
    "list2 = tokenize('Matt Boehm')\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity_case_insensitive(list1, list2):\n",
    "    s1 = set(map(str.upper, list1))\n",
    "    s2 = set(map(str.upper, list2))\n",
    "    return float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "list1 = ['Matt', 'Böhm']\n",
    "list2 = ['Matt', 'Boehm']\n",
    "\n",
    "similarity = jaccard_similarity_case_insensitive(list1, list2)\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sim = jaccard_similarity_case_insensitive('DOG', 'dog')\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
